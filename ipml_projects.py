# -*- coding: utf-8 -*-
"""IPML_projects (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOQhhEMmQw2t8D0pgBtsD3xTZ7IcW15a
"""

#to downloaf data from drive
!gdown 1wbHo6oi_eNn9vMZcAHNLCW9aBM5pCOQo

!gdown 16xmssl0ciRMQ_3Co_uzw_iN-_Q0X-urz

#install reposirty
!pip install tensorflow-addons==0.16.1

#unziping dataset
!unzip /content/file.zip -d /content/

!gdown 1RzF8FIE5HTKszX2bruP07OEehLojktzo

import os
import glob
import random
import numpy as np
import pandas as pd
from google.colab import files

import tensorflow_addons as tfa
import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D,Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras import regularizers
from sklearn.metrics import confusion_matrix

# from tqdm import tqdm

from PIL import Image

from tensorflow.keras.utils import to_categorical

import seaborn as sns
import matplotlib.image as img
import matplotlib.pyplot as plt

"""# Setting up the path and loading csv files"""

train_csv = pd.read_csv("/content/training_set.csv")
# test_csv = pd.read_csv("Human Action Recognition/Testing_set.csv")

train_fol = glob.glob("/content/content/HumanActionRecognition/train") 
# test_fol = glob.glob("Human Action Recognition/test/*")

#dataset dscription
train_csv.label.value_counts()

#pie chart for datset
import plotly.express as px
l = train_csv.label.value_counts()
fig = px.pie(train_csv, values=l.values, names=l.index, title='Distribution of Human Activity')
fig.show()

#filename contains files and situations contains labels
filename = train_csv['filename']

situation = train_csv['label']

"""# Creating a function to random take a image and display it with its label"""

def disp():
    num = random.randint(1,10000)
    imgg = "Image_{}.jpg".format(num)
    train = "/content/content/HumanActionRecognition/train/"
    if os.path.exists(train+imgg):
        testImage = img.imread(train+imgg)
        plt.imshow(testImage)
        plt.title("{}".format(train_csv.loc[train_csv['filename'] == "{}".format(imgg), 'label'].item()))

    else:
        #print(train+img)
        print("File Path not found \nSkipping the file!!")

disp()

disp()

"""# Processing data"""

list_of_class=train_csv['label'].factorize()[1]

total_class={"sitting":0,"using_laptop":1,"hugging":2 ,"sleeping" :3,"drinking":4,"clapping" :5,"dancing":6,
"cycling":7,"calling":8,"laughing":9,"eating" :10,"fighting":11,"listening_to_music":12,"running":13,"texting":14}

img_data = []
test_data=[]
img_label = []
test_label=[]



for i in list_of_class:
  df_new = train_csv[train_csv['label'] == i]
  filename = df_new['filename']
  situation = df_new['label']
  cout=0
  length = len(filename)
  for i in filename.index:
    t = '/content/content/HumanActionRecognition/train/' + filename[i]
    temp_img = Image.open(t)
    temp_img=np.asarray(temp_img.resize((200,200)))
    if(cout<1100):
      img_data.append(temp_img)
      img_label.append(total_class[situation[i]])
      cout+=1
    else:
      test_data.append(temp_img)
      test_label.append(situation[i])

iii = img_data
iii = np.asarray(iii)
type(iii)

test = test_data
test = np.asarray(test)
type(test)

print(iii.shape,test.shape)

train_csv['label'].factorize()[0]

y_train = to_categorical(np.asarray(img_label))
print(y_train[0])

x_train_t, x_val_t, y_train_t, y_val_t = train_test_split(iii, y_train, test_size=0.2, random_state=42)

vgg_model = Sequential()


pretrained_model= tf.keras.applications.EfficientNetB7(include_top=False,
                   input_shape=(200,200,3),
                   pooling='avg',classes=15,
                   weights='imagenet'
)


for layer in pretrained_model.layers:
        layer.trainable=False


vgg_model.add(pretrained_model)
vgg_model.add(Flatten())
vgg_model.add(Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.01)))
vgg_model.add(Dense(15, activation='softmax'))

#model compilation
vgg_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])

#model summary
vgg_model.summary()

history = vgg_model.fit(x_train_t, y_train_t, validation_data=(x_val_t, y_val_t), epochs=20)

# Retrieve the training and validation loss values
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Generate x-axis values (epochs)
epochs = range(1, len(train_loss) + 1)

# Plotting
plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

#model training
history = vgg_model.fit(iii,y_train, epochs=20)

#save model
vgg_model.save_weights("model2.h5")

#loss graph with no of epochs
losss = history.history['loss']
plt.plot(losss)

#accuracygraph
accu = history.history['accuracy']
plt.plot(accu)

"""# Custom Testing"""

!gdown 1YGfPWTArww25SjsivGVsaPzhgmHKiOTF

vgg_model.load_weights("/content/ipmlmerge.h5")

# Function to predict

def test_predict(test_image):
    result = vgg_model.predict(np.asarray([test_image]))

    itemindex = np.where(result==np.max(result))
    prediction = itemindex[1][0]
    # print("probability: "+str(np.max(result)*100) + "%\nPredicted class : ", list_of_class[prediction])
    return list_of_class[prediction]
    # image = img.imread(test_image)
    # plt.imshow(image)
    # plt.title(prediction)

print(test.shape)

#code to predict on split test
count=0;
predicted_labels = []
for i in range(len(test)):
  result=test_predict(test[i])
  predicted_labels.append(result)
  if(result==test_label[i]):
    count+=1;
print(count,count/len(test_data))

# Calculate the confusion matrix
cm = confusion_matrix(test_label, predicted_labels)

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

#savemodelweights and arichtecture
files.download('/content/model2.h5')

#randomto test
def test_random():
    num = random.randint(1,test.shape[0])
    plt.imshow(test[num])
    plt.show()
    result = vgg_model.predict(np.asarray([test[num]]))
    itemindex = np.where(result==np.max(result))
    prediction = itemindex[1][0]
    print("probability: "+str(np.max(result)*100) + "%\nPredicted class : ", list_of_class[prediction])

test_random()

"""### Test folder image testing """

# this code is used to create the image directories for custom testing... no need to run now

test_fol = glob.glob("Human Action Recognition/test/*")

len(test_fol)

!gdown 1iIqg1vpJ1mURIZtUHUVsOza9J8yDdKmO

mkdir test

# new_model = tf.keras.models.load_model('/content/model1.h5')

test1_data=[]
for i in test_fol:
  temp_img = Image.open(i)
  test1_data.append(np.asarray(temp_img.resize((200,200))))

print(len(test1_data))

import cv2
count=0
for i in test1_data:   
    result = vgg_model.predict(np.asarray([i]))
    itemindex = np.where(result==np.max(result))
    prediction = itemindex[1][0]
    if(os.path.exists("/content/test/"+list_of_class[prediction])):
      cv2.imwrite("/content/test/{}/{}.jpeg".format(list_of_class[prediction],str(count)+"t"),i)
    else:
      os.mkdir("/content/test/"+list_of_class[prediction])
      cv2.imwrite("/content/test/{}/{}.jpeg".format(list_of_class[prediction],str(count)+"t"),i)
    count+=1

!zip -r /content/file.zip /content/test